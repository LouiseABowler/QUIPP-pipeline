{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulated Annealing for Microsimulation\n",
    "\n",
    "We apply the simulated annealing algorithm to a **microsimulation** task in this short example. Microsimulation can be used to combine individual-level and aggregate datasets that are available at different spatial resolutions in order to produce a synthetic population where every individual within has a detailed set of characteristics.\n",
    "\n",
    "This may occur in a scenario where individual-level data is available over a large area (e.g. samples from the census), but the data is needed on a smaller spatial scale. If the numbers of people with certain properties are known at a finer spatial resolution from another data source, it is possible to generate a synthetic population at a smaller spatial scale where the properties of the people within are consistent with the second data source.\n",
    "\n",
    "The synthetic population generated by microsimulation techniques can be used in further simulations, such as agent-based models, where the characteristics of each simulated individual in the population must be known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from simanneal import Annealer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimpleWorld\n",
    "\n",
    "We'll work with a very simple dataset, \"SimpleWorld\", for the first part of this demonstration. The example data comes from *Spatial Microsimulation with R*, by Robin Lovelace and Morgane Dumont.\n",
    "\n",
    "### Load the data\n",
    "\n",
    "We'll first load two files that contain counts of people with certain attributes who reside in three separate regions. These attributes - here, age and sex - form the **constraints** of our problem.\n",
    "\n",
    "In the **age** dataset, we have counts of people aged below 50, and 50 and above. The three rows of the table correspond to the three different regions. We can see that there are slightly more younger people in regions 0 and 2, and many more older people in region 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = pd.read_csv(os.path.join(os.getcwd(), \"..\", \"..\", \"datasets\", \"SimpleWorld\", \"age.csv\"))\n",
    "age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **sex** dataset is similarly formatted. The number of males and females are close two equal in regions 0 and 1, while there are far more females than males in region 2.\n",
    "\n",
    "We would expect our synthetic dataset to reflect these characteristics to give younger population with more females in region 2, and so on for the other regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex = pd.read_csv(os.path.join(os.getcwd(), \"..\", \"..\", \"datasets\", \"SimpleWorld\", \"sex.csv\"))\n",
    "sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have some individual-level data. Each individual has properties which match those in the constraints, along with other properties which are of interest to us. In this example, we would like to generate a synthetic population for each of the three regions where the individuals within have an exact age and an income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = pd.read_csv(os.path.join(os.getcwd(), \"..\", \"..\", \"datasets\", \"SimpleWorld\", \"ind-full.csv\"))\n",
    "ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the optimisation problem\n",
    "\n",
    "In this example, we use an implementation of a simulated annealing algorithm from the `simanneal` package. We use this implementation as the one in the widely-used `scipy` package is deprecated, and both it and subsequent implementations of similar algorithms in `scipy` are not able to accept discrete choices for the inputs.\n",
    "\n",
    "We initialise the class with the constraints a list of the individuals and their attributes. We also define two functions in the class:\n",
    "- `move()` Selects one person in the synthetic population and swaps their ID to an alternative from the population of individuals.\n",
    "- `energy()` Computes the total absolute error, which we want to minimise during the optimisation process. The error is defined as\n",
    "$$ \\sum_c\\sum_o |S_{c,o} - E_{c,o}| $$\n",
    "where $c$ is the constraint type, $o$ is the option for that constraint, and $S$ and $E$ are the counts of these combinations of $c$ and $o$ in the synthetic and expected (constraint) populations respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MicrosimulationOptimiser(Annealer):\n",
    "    \"\"\"A class for performing simulated annealing on the microsimulation problem\"\"\"\n",
    "    \n",
    "    def __init__(self, inds, *cons, logs=False, pop_size=None):\n",
    "        \n",
    "        self.logs = logs\n",
    "        \n",
    "        # Check that the constraints are consistent - must contain same number of individuals\n",
    "        for i, con in enumerate(cons):\n",
    "            if i == 0:\n",
    "                population_count = sum(con)\n",
    "            else:\n",
    "                assert sum(con) == population_count\n",
    "                \n",
    "        if pop_size is None:\n",
    "            self.n_synth_individs = population_count\n",
    "        else:\n",
    "            self.n_synth_individs = pop_size\n",
    "    \n",
    "        self.individs = inds       # Use term individs rather than inds to avoid confusion with plural of id!\n",
    "        self.cons = cons\n",
    "        \n",
    "        # Give each synthetic individual a random ID from the seed individual dataset, then set up the optimiser class\n",
    "        state = np.random.choice(range(self.individs.shape[0]), self.n_synth_individs)\n",
    "        super(MicrosimulationOptimiser, self).__init__(state)\n",
    "    \n",
    "    def move(self):\n",
    "        \n",
    "        # Select individual to be changed\n",
    "        index_change = np.random.randint(self.n_synth_individs)\n",
    "        \n",
    "        if self.logs:\n",
    "            print(\"Changing individual {}; was {}: \\t {}\".format(index_change, self.state[index_change], self.state))\n",
    "        \n",
    "        # Give this individual a new id, which must be different from its current id\n",
    "        new_id = np.random.choice(self.individs.shape[0]-1)\n",
    "        if new_id < self.state[index_change]:\n",
    "            self.state[index_change] = new_id\n",
    "        else:\n",
    "            self.state[index_change] = new_id + 1\n",
    "            \n",
    "        if self.logs:\n",
    "            print(\"now {}: \\t\\t\\t\\t {}\".format(self.state[index_change], self.state))\n",
    "        \n",
    "    def energy(self):\n",
    "        \n",
    "        # Generate the synthetic population: state tells us which individuals are present by their index in inds\n",
    "        synthetic_individs = self.individs[self.state,]\n",
    "        \n",
    "        total_abs_error = 0\n",
    "        \n",
    "        # Count up how many individuals there are with each property \n",
    "        # and compare to the counts in the constraint tables\n",
    "        for s_individs, con in zip(synthetic_individs.transpose(), self.cons):\n",
    "            \n",
    "            # Count how many simulated people have each option for this constraint\n",
    "            con_id, con_id_counts = np.unique(s_individs, return_counts=True)\n",
    "            \n",
    "            # Some options might be missing - add their label and frequency (0) to the list manually\n",
    "            missing = np.where(np.isin(range(con.shape[0]), con_id, invert=True))\n",
    "            if missing[0].size != 0:\n",
    "                \n",
    "                if self.logs:\n",
    "                    print(\"Constraint IDs {} are missing in constraint table {}\".format(missing[0], con_id))\n",
    "                    for i, c in zip(con_id, con_id_counts):\n",
    "                        print(\"[{}, {}]\".format(i, c))\n",
    "                \n",
    "                con_id = np.append(con_id, missing[0])\n",
    "                con_id_counts = np.append(con_id_counts, np.zeros_like(missing[0]))\n",
    "\n",
    "                if self.logs:\n",
    "                    print(\"Added missing constraint IDs:\")\n",
    "                    for i, c in zip(con_id, con_id_counts):\n",
    "                        print(\"[{}, {}]\".format(i, c))\n",
    "                    \n",
    "                # Sort the resulting counts array\n",
    "                con_id_counts = con_id_counts[np.argsort(con_id)]\n",
    "                \n",
    "                if self.logs:\n",
    "                    con_id = con_id[np.argsort(con_id)]\n",
    "                    print(\"Sorted constraints:\")\n",
    "                    for i, c in zip(con_id, con_id_counts):\n",
    "                        print(\"[{}, {}]\".format(i, c))\n",
    "                    \n",
    "            abs_error = np.sum(np.abs(con - con_id_counts))\n",
    "            total_abs_error += abs_error\n",
    "\n",
    "            if self.logs:\n",
    "                print(\"Constraint counts: {}\".format(con))\n",
    "                print(\"Synthetic counts: {}\".format(con_id_counts))\n",
    "                print(\"Error: {}\".format(abs_error))\n",
    "            \n",
    "        return total_abs_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we run the optimisation process, we need to reformat the table of individuals. Our seed population should have one row per person, one column for each of the constraints. The values in each column indicate which of the options for that constraint each person has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_conditions = [ind[\"age\"] < 50, ind[\"age\"] >= 50]\n",
    "sex_conditions = [ind[\"sex\"] == \"m\", ind[\"sex\"] == \"f\"]\n",
    "\n",
    "# Now create an array that holds the individuals and how their properties correspond to the constraints\n",
    "ind_array = np.array([np.select(age_conditions, range(len(age_conditions)), default=None),\n",
    "                      np.select(sex_conditions, range(len(sex_conditions)), default=None)]).transpose()\n",
    "\n",
    "print(\"Seed population:\\n {}\".format(ind_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column of the array indicates the age band of each person in the seed population: <50 (0) or >=50 (1). The second column indicates the sex: male (0) or female (1). The indices in this array correspond to the column used for that characteristic in each of the constraint arrays.\n",
    "\n",
    "Before we start, we'll set a random seed for reproducibility and choose the region for which we want to generate a population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "region = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can prepare the optimiser. We provide the following arguments:\n",
    "- An array of individuals as shown above.\n",
    "- Arrays containing the constraints (also converted to numpy arrays). The order of the constraints corresponds to the column ordering in the first argument.\n",
    "\n",
    "When we view the initial state, we can see that we have an array of individuals (by default, the same number given in the constraints) with a random set of IDs, which correspond to individuals from the seed population. The optimiser will change the IDs in this array until it generates a population which is consistent with (or as close as possible to) the constraints we specified earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = MicrosimulationOptimiser(ind_array, age.to_numpy()[region], sex.to_numpy()[region])\n",
    "print(\"Initial state:\", opt.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run the simulated annealing algorithm. We change `Tmax` and `Tmin` from their defaults of 25,000 and 2.5 as the documentation for the `simanneal` package recommends ~98% acceptance of moves at `Tmax` and close to 0% improvement at `Tmin`. These changes were made manually, and will need revising for other datasets. (In this case, the defaults do still give reatively good results - comment out the next two lines to try.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.Tmax = 100\n",
    "opt.Tmin = 0.1\n",
    "population_ids, error = opt.anneal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs from the annealing algorithm are a list of IDs, corresponding to individuals from our sample population who are included in our synthetic population, and the total absolute error in the population. If it is zero, our population should exactly fulfil the constraints we specified earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_population = ind.iloc[population_ids]\n",
    "synthetic_population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's compare the properties of our synthetic population with the original. The properties that we used for constraints are age (under/over 50) and sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Region {}\".format(region))\n",
    "\n",
    "print(\"\\nAge\")\n",
    "print(\"Under 50: expected {}, got {}\".format(age[\"a0.49\"].iloc[region], \n",
    "                                             len(synthetic_population[synthetic_population[\"age\"] < 50])))\n",
    "print(\"50 and over: expected {}, got {}\".format(age[\"a.50+\"].iloc[region], \n",
    "                                                len(synthetic_population[synthetic_population[\"age\"] >= 50])))\n",
    "\n",
    "print(\"\\nSex\")\n",
    "print(\"Males: expected {}, got {}\".format(sex[\"m\"].iloc[region], \n",
    "                                          len(synthetic_population[synthetic_population[\"sex\"] == \"m\"])))\n",
    "print(\"Females: expected {}, got {}\".format(sex[\"f\"].iloc[region], \n",
    "                                            len(synthetic_population[synthetic_population[\"sex\"] == \"f\"])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
